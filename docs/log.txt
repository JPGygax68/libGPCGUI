2015-02-16
==========

I need a way to define the aspect of widgets. There need not be a full theming engine behind this right from the start, but it must definitely be possible to introduce one later on.

I've defined an enum "ViewState" that lists the (visual) states a widget can be in. As far as I can think of right now, these are:

- default
- hover
- active (usually means "being clicked")
- deactivated

There are other states that specific widgets can have, but this state is one that all widgets must have [note: I'm not quite happy with the term "view state"].

I now need a way to associate an arbitrary number of properties, of arbitrary type, with each of these states. This will be the basis for my "simple theming", which only uses basic colors to render widgets. (Other theming implementations might not directly associate properties [or property variants] with view states.)

What I need is a template that is able to store a different value for each view state, but is capable of falling back on an algorithm to determine values that are not defined - callbacks or trait-like classes should be used here, or possibly the CRTP pattern.

To implement actual theming later on, the template should be made cascadable: a boolean determines whether a property object holds its own set of values, or obtains them from another property object via a pointer or reference.

Actually, thinking about it, the first implementation of the Property template may not need to store multiple variants; the algorithmic path may be enough to start with.
Then again: there is no algorithmic way to obtain a bold font from a regular one. (But yet again, emboldening a font as a visual highlight is a terrible, terrible idea.)


2015-02-15
==========

I have just spent a few hours trying, and failing, to create a Theme implementation based on partial template specialization.

The idea was to use the CRTP to define themes at compile-time, with the base class providing default variations on the basic colors provided in the derived class. Apparently though, there are limitations in the C++ standard, even C++11, that prevent this.

Since this does not work, and the approach also has the drawback of precluding the option to override color definitions at runtime, I'm going to try a more down-to-earth approach next.

One simple idea is to use a single entry point per theme element type (they will mostly be colors), that is given the element ID (e.g. BORDER) and the state (e.g. DEFAULT, HOVER, etc.). These methods could be made virtual. The base class would also use pure virtual method definitions by which to get basic colors (i.e. for the DEFAULT state of an element) from which it will derive the colors for the other states. A derived theme implementation can then choose to override that behaviour and provide, for example, a fine-tuned value for the HOVER state.

Another approach would be to define a data format that can provide values for every theme element in every state, but is only required to do so for the DEFAULT state. If no value is provided for one of the other states, the Theme class would then fall back to deriving that value algorithmically.

2015-02-03
==========

- One thing I had not thought about yet: I just noticed that Windows (among else) uses smooth transitions to indicate view state changes (e.g. hovering/leaving a button changes its color, but smoothly)

- Maybe it's time, at this point, to think about theming.
  - Generalize the notion of "view state", so that change to any view state would automatically trigger a repaint ?

- I think animations should be kept outside of view state proper - though it must be able to trigger repaints.

- In some scenarios, it might make sense to do repaints immediately after the event triggering them - perhaps this could be a template specialization as well ?

---

### Theming - brainstorming

- Definition: make the association between view states and visual aspect customizable.

- Define arithmetics for colors ?

- Mix in theming via multiple inheritance ?

- For right now, use color interpolation. E.g. button:
  - define base colors (border, face)
  - derive hover and "active" variants (button down)
  - Theme:
    - area border color, inactive
    - area border color, "default" (for default button in a dialog)
    - area background color, inactive
    - area background color, hovered
    - area background color, focused
    - area background color, active (button down)

- All these colors should come from a theme definition that can be used by all widgets.

- Injecting "theming engine" into widget implementations
  - Same class for all widgets, or specific to widget type ?
  - Interface methods:
    - drawBorder()
    - drawBackground()
    - drawOverlay()

2015-01-28
==========

Quick notes:

- I've implemented a method to draw bevels in the Widget class. I'm not sure this is the right place; maybe a separate toolbox would be better.

- I'm still looking for a better term to replace "area" to express the combination of a width and a height. Not sure right now why I dissed "extents".

- I've defined Renderer::rgba_to_native() to be static methods. This could save some cycles because needed native colors can now easily be prepared as static constant values.

2015-01-26
==========

- GUI: "forced repaint" mode for when using double buffering or buffer must be redrawn for any other reason ?
  - Renderer parameter ? const parameter ?

- Order: layout - graphic resources - paint

- TODO: x_abs and y_abs are ill-named

2015-01-25
==========

Though it's very easy to store a collection of event handlers using std::function<> and std::vector<>, there seems to be no easy way to remove a handler from the collection due to the fact that std::function<> does not support an equality operator.

So, should I:

a) altogether drop the idea of supporting multiple event handlers per event ?
b) support detaching all event handlers at the same time ?

I've opted for (b) for now.

Next question: should event handlers get a pointer to the widget ? I think YES, as that would allow assigning a shared event handler to a collection of widgets.

---

Another question: how about providing events as widget "properties" (i.e. methods returning object references), so that one could write:

  my_button.mouseExit().addHandler( ... );
  
This would also remove the need for code duplication (but does it incur a footprint cost because of a need to point back to the widget?).

---

Just noted an inconvenience - when specifying lambda event handlers, one needs to specify the full type of the Widget parameter, which can be inconvenient as it needs template parameters.

In a real future application, the widget types will likely come from an already available templated struct. Still, it might be beneficial to support overloads of addXXXXHandler() that just throw away that parameter (and possibly the others as well) to support unencumbered user code. (Of course, a full parameterless callback only makes sense if the event is "signal-like" - i.e., the fact that it's been fired at all can be considered useful information in and of itself.)


2015-01-20 (evening)
==========

How to handle fonts and other resources that must eventually be handled by the GPU ?

On the GUI side, fonts are actually (pointers to) RasterizedFont objects. A GPU-based renderer will usually have to process those objects and upload some of that data (namely, the pixels) into GPU memory, returning a handle to the caller that the caller must provide again to actually render text. I call the process of creating a renderer-specific handle from a RasterizedFont object "registering" the font with the renderer (but perhaps a better term can and should be found).

Registering fonts is something that requires an active renderer, yet does not actually produce output. Because of that, it is probably a good idea to give user code a chance to trigger this independently of the rendering itself.

The question arises whether or not a widget should be allowed to change its font(s) when it has already been renderered (and thus has obtained a renderer-specific handle for its font). The alternative would be to mandate that the widget be re-created in such as case. This might make the implementation of a GUI designer somewhat less easy, especially since the question of serialization has not been discussed at all yet.

Assuming that yes, widgets can change fonts, the question arises how to manage this. Assigning a different rasterized font must trigger two things: releasing the old handle, and obtaining a new one. Both should take place before the next rendering pass, but not as a part of said rendering. And it cannot be done right away (synchronously), because the renderer is only available during rendering.

Before going further, I must question that assertion. I have trouble coming up with a scenario where it would be difficult to get access to the renderer at an arbitrary time. Though it is conceivable to have a renderer that is incapable of doing any drawing except when being called from the windowing system, it is very unlikely that the renderer would not still be able to access its resource pool at any time - that would almost imply that the resource pool is only available from a specific thread. Which, come to think of it, is actually a possibility - is there a CPU/GPU combination where only a specific core is able to communicate with the GPU ?

Thinking (and Googl'ing) some more, using a GL context (on which a renderer typically sits) from any thread *does* invite potential problems. In Windows for example, it is stated that a given GL context should only be made "current" in one thread at a time.

So, to sum up, there are two ways to go here:

- Decide that the renderer can be used at any time. This may make it necessary that the root widget call back to user code in order to "lock" the renderer. The advantage is that there is no need to defer registering and unlinking of renderer resources.

- Or provide hooks for user code to call at opportune times (possibly, though not ideally, from different threads than the rendering thread). This implies either keeping lists of things to allocate and free, or setting "dirty" flags that propagate up the widget tree up to the root widget.


2015-01-20
==========

The current approach to size calculations / layouting has a fundamental problem: it relies on the renderer for calculating text extents, which is nearly always needed when calculating the size and internal layout of a widget. 

This is wrong in the sense that it is an unnecessary dependency: the pixel size of a piece of text will never depend on what renderer is being used to display things.

That in itself is not a show-stopper. However, it makes it impossible to do layout calculations without passing the renderer around, which means that the "preferred size" of a widget cannot be treated like a (computed and read-only) property, but can only be obtained during an explicit layouting pass. This is impractical; in particular, it would make GUI designer tools cumbersome.


2015-01-19
==========

Todos at this point:

- Decide how to handle auto-sizing of widgets:
  - minWidth(), minHeight(): computed, set externally, or both ?
  - or just silently adjust externally set size ?
  - or interpret size = 0 as "auto" ?
  
- Trigger repaint when view-model state changes
  - but avoid recursion crash
  - actually a simple button doesn't have state
  
- Trigger repaint when view state changes
  -> implement display region invalidate
  
- Implement alignment
